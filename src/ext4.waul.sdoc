Ext4 filesystem implementation | Spencer Tipping
Licensed under the terms of the MIT source code license

Introduction.
This module implements a simple asynchronous ext4 driver for node.js Buffer objects and Javascript arrays. You can use this to read and write ext4 volumes stored in files or on block devices,
and because it is fundamentally asynchronous you can tunnel all of the data over an RPC connection.

This implementation has a few oddities. First, a lot of ext4 features are unimplemented, including some important ones like journaling. Second, the block allocator is very willing to fragment
files if it makes the volume more compact. This is at odds with ext4's delayed allocation, block group balancing, and sparse layout. Third, this implementation continuously resizes the volume
as blocks are allocated and freed. Finally, it allows you to force aspects of extent layout and get low-level information like where a file's data starts. This helps when implementing
bootloaders.

Right now it doesn't implement hashed directories, but in the future I will probably implement this.

caterwaul.module('ext4', 'js_all', function ($) {

Binary data structure definitions.
These are taken basically verbatim from http://ext4.wiki.kernel.org.

  $.ext4 = "$.ext4.init.apply(this, arguments)".qf /-$.merge/ capture [

    superblock      = $.struct().u32l('inodes blocks reserved_blocks free_blocks free_inodes first_data_block log_of_block_size obsolete_log_fragment_size blocks_per_group').
                                 u32l('obsolete_fragments_per_group inodes_per_group mount_time write_time').u16l('mounts max_mounts magic state error_behavior minor_revision_level').
                                 u32l('last_check check_interval creator_os revision_level').u16l('default_uid default_gid').u32l('first_inode').u16l('inode_size block_group_number').
                                 u32l('feature_compatible feature_incompatible feature_ro_compatible').ascii('uuid')(16).ascii('volume_name')(16).ascii('last_mounted')(64).
                                 u32l('algorithm_usage_bitmap').u8('preallocate_blocks preallocate_dir_blocks').u16l('reserved_gdt_blocks').u8('journal_uuid', 16).
                                 u32l('journal_inode journal_device last_orphan').u32l('hash_seed', 4).u8('default_hash_version jni_backup_type').u16l('group_descriptor_size').
                                 u32l('default_mount_options first_meta_block_group mkfs_time').u32l('journal_block_backup', 17).u32l('blocks_high reserved_blocks_high free_blocks_high').
                                 u16l('minimum_inode_size inode_reserve_size').u32l('flags').u16l('raid_stride mmp_interval').u32l('mmp_block', 2).u32l('raid_stripe_width').
                                 u8('log_of_flexible_block_group_size').u8('reserved_char_pad').u16l('reserved_pad').u32l('kb_written', 2).u32l('snapshot_inode snapshot_id').
                                 u32l('snapshot_reserved_block_count', 2).u32l('snapshot_list_inode error_count first_error_time').u32l('first_error_inode').u32l('first_error_block', 2).
                                 ascii('first_error_function')(32).u32l('first_error_line last_error_time last_error_inode last_error_line').u32l('last_error_block', 2).
                                 ascii('last_error_function')(32).ascii('mount_options')(64).u32l('user_quota_inode group_quota_inode overhead_blocks checksum').u32l('reserved', 108)
                 -se- it.size() /-must_be/ 1024,

    block_group     = $.struct().u32l('block_bitmap inode_bitmap inode_table').u16l('free_block_count free_inode_count used_directory_count flags').u32l('reserved', 2).
                                 u16l('unused_inodes checksum').u32l('block_bitmap_high inode_bitmap_high inode_table_high').u16l('free_block_count_high free_inode_count_high').
                                 u16l('used_directory_count_high unused_inodes_high').u32l('reserved2', 3)
                 -se- it.size() /-must_be/ 64,

    inode           = $.struct().u16l('mode uid').u32l('size atime ctime mtime dtime').u16l('gid link_count').u32l('block_count flags version').u8('i_block', 60).
                                 u32l('generation extended_attribute_block size_high obsolete_fragment_address').u16l('block_count_high extended_attribute_block_high uid_high gid_high').
                                 u32l('reserved').u16l('extra_inode_size pad_1').u32l('ctime_extra mtime_extra atime_extra crtime crtime_extra version_high')
                 -se- it.size() /-must_be/ 156,

    block_map       = $.struct().u32l('direct', 12).u32l('indirect_block_1 indirect_block_2 indirect_block_3'),
    extent_tree     = $.struct().u16l('magic entries max depth').u32l('generation'),
    extent_index    = $.struct().u32l('block leaf').u16l('leaf_high unused'),
    extent_leaf     = $.struct().u32l('block').u16l('length start_high').u32l('start_low'),

    // Note that this directory entry structure corresponds to ext4_dir_entry_2, not the original ext4_dir_entry.
    directory_entry = $.struct().u32l('inode').u16l('record_length').u8('name_length').u8('file_type').ascii('name')(255),

    htree_root      = $.struct().u32l('dot_inode').u16l('dot_record_length').u8('dot_name_length dot_file_type').u8('dot_name', 4).
                                 u32l('dotdot_inode').u16l('dotdot_record_length').u8('dotdot_name_length dotdot_file_type').u8('dotdot_name', 4).
                                 u8('hash_version info_length indirect_levels unused_flags').u16l('limit count').u32l('block'),

    htree_node      = $.struct().u32l('fake_inode').u16l('fake_record_length').u8('name_length file_type').u16l('limit count').u32l('block'),
    htree_entry     = $.struct().u32l('hash next')]

  -where [must_be(x, y) = x === y || console.log('\033[1;31m >> #{x} was expected to be #{y}\033[0;0m')],

High-level data structure definitions.
These parse and manipulate the low-level data structures on disk to provide a structured filesystem interface. The interface presented here is pretty low-level and doesn't support things like
permission checking. The upside to this shallow abstraction is that you can do things like talk to the block allocator directly, which is useful for reducing fragmentation and writing
bootloaders.

To create a filesystem against a node.js buffer called disk_buffer:

| fs = $.ext4(read, write)
       -where [read(offset, length) = $.future()(disk_buffer.slice(offset, offset + length)),
               write(xs, offset)    = xs *![disk_buffer[xi + offset] = x] -seq -then- $.future()(xs.length)]

In this case all of the futures are resolved immediately, but you can resolve them asynchronously too. Note that neither read() nor write() is allowed to assume anything specific to node.js
Buffer instances unless you know you're running exclusively on node.js. The reason is that ext4 images should be portable to the browser and accessible via RPC.

  ($.ext4.init(read, write) = this instanceof $.ext4 ? this -se [it.read = read, it.write = write] : new $.ext4(read, write)) -se- $.ext4.prototype /-$.merge/ methods()

  -where [methods()                                = capture [superblock() = superblock(this.read, this.write),
                                                              root()       = this.superblock() /~flat_map/ "_.root()".qf],

Locking.
Some locking needs to happen because not all operations can be completed with just one sequential disk operation (and even if they could, order of disk operations is not well-defined). Each
inode can be locked independently; this happens when any write operation happens on the inode itself (not the data; access to this is not synchronized in any way). Locking an inode prevents
the inode, its extent map, and for directories only, its data, from being modified by another request. An inode is locked when a a file is expanded or truncated.

Locks are implemented transparently as flat_map stages in writing futures. That is, for a write operation w() -> future that requires locking:

| lock(w)() = mutex_free_future.flat_map(w)

          superblock(r, w)                         = r(1024, 1024) /~map/ "_ / r /-become_superblock/ w".qf,
          become_superblock(sb, r, w, sb = result) = $.ext4.superblock.decode(sb)
                                          /-$.merge/ wcapture [real_block_size()    = sb._real_block_size   || (sb._real_block_size   = 1 << 10 + sb.log_of_block_size),
                                                               inodes_per_block()   = sb._blocks_per_inode  || (sb._blocks_per_inode  = real_block_size() / sb.inode_size >>> 0),
                                                               block_group_size()   = sb._block_group_size  || (sb._block_group_size  = $.ext4.block_group.size()),
                                                               block_group_count()  = sb._block_group_count || (sb._block_group_count = Math.ceil(sb.blocks / sb.blocks_per_group)),
                                                               block_group_offset() = sb.log_of_block_size ? 1 : 2,

                                                               read_block(n)        = r(n * real_block_size(), real_block_size()),
                                                               read_block_group(n)  = read_block(block_group_offset() + n * block_group_size()) /~map/ "_ /-become_block_group/ sb".qf,
                                                               read_inode(n)        = read_block_group((n - 1) / sb.inodes_per_group >>> 0)
                                                                          /~flat_map/ "_.read_inode((n - 1) % sb.inodes_per_group)".qf,

                                                               root()               = read_inode(2)],                                   // Root directory position is fixed

          become_block_group(g, sb, g = result)       = $.ext4.block_group.decode(g)
                                             /-$.merge/ wcapture [read_inode(n) = sb.read_block(g.inode_table + (n / sb.inodes_per_block() >>> 0))
                                                                           /~map/ "_ / (n % sb.inodes_per_block() * sb.inode_size) /-become_inode/ sb".qf],

          become_inode(i, o, sb, i = result)          = $.ext4.inode.decode(i, o)
                                             /-$.merge/ wcapture [permission_bits()  = i.mode & 0xfff,
                                                                  extents_enabled()  = i.flags & 0x80000,                               // We only support these (not block maps)
                                                                  hashed_directory() = i.flags & 0x1000,                                // We don't support these yet
                                                                  file_type()        = '#pc#d#b#f#l#s'.charAt(i.mode >>> 12),           // # means invalid/unknown/deleted

                                                                  data_blocks()      = n[i.block_count] *[data_block(x)] /seq /!$.future,
                                                                  data()             = data_blocks() /~map/ "_ *~![x] -seq -re- it.slice(0, i.size)".qf,
                                                                  read_directory()   = data() /~map/ directory_entries_in,

                                                                  extent_root()      = i.i_block /-become_extent_tree/ sb,
                                                                  data_block(n)      = extent_root().data_block(n)],

Directory parsing.
Right now this driver only supports linear-scan directories; there is no support for ext3/4 htrees yet. Directory entries are stored as variable-sized structures in individual disk blocks;
each one contains an inode reference. We stop scanning when we hit one with an inode of 0.

          directory_entry(block_data, offset)         = $.ext4.directory_entry.decode(block_data, offset) -se [it.size() = it.record_length || 8,
                                                                                                               it.name   = it.name.substr(0, it.name_length)],
          directory_entries_in(block_data)            = 0 *~![x < block_data.length - 4] [result.push(d), x0 = x, x + d.size(), where [d = directory_entry(block_data, x)]] /seq
                                                        -then- result %[x.inode] /seq
                                                        -where [result = []],

Extent tree implementation.
Extent trees have the desirable property that all immediate children are available synchronously. Constructing each child is an asynchronous operation, as is, obviously, retrieving the data.

          become_extent_tree(e, sb, t = result)       = $.ext4.extent_tree.decode(e)
                                             /-$.merge/ wcapture [child_structure() = t._child_structure || (t._child_structure = t.depth ? "e / _ /-become_extent_index/ sb".qf
                                                                                                                                          : "e / _ /-become_extent_leaf/  sb".qf),

                                                                  children()        = n[t.entries] *[child_structure()($.ext4.extent_tree.size() + xi * 12)] -seq,

                                                                  container_of(b)   = next |[x.block > b ? x0 : (x0 = x, false)] |seq |or [next[next.length - 1]] |where [next = children()],
                                                                  data_block(n)     = container_of(n).data_block(n)],

          become_extent_index(e, o, sb, e = result)   = $.ext4.extent_index.decode(e, o)
                                             /-$.merge/ wcapture [block_data()  = sb.read_block(e.leaf) /-become_extent_tree/ sb,
                                                                  data_block(n) = block_data() /~flat_map/ "_.data_block(n)".qf],

          become_extent_leaf(e, o, sb, e = result)    = $.ext4.extent_leaf.decode(e, o)
                                             /-$.merge/ wcapture [data_block(n) = sb.read_block(e.start_low + n - e.block)]],

  where [fail(reason) = raise [new Error(reason)]]});
